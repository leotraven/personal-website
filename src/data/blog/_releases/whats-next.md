---
author: Leo Traven
pubDatetime: 2026-02-25T18:22:00Z
modDatetime: 2026-02-25T18:22:00Z
title: Black Swans and AI
slug: black-swans-and-ai
featured: false
draft: false
tags:
  - ai
  - agents
  - blackswan
description: Why I think the next step change in AI is unpredictable.
---

<!-- Situation -> Complication -> Question -> Answer -->

### TL;DR:
- Our lifes are mostly influenced by unpredictable events, which are called Black Swans
- Although people create stories of them having been clear from the start, they are not
- Instead of looking at predictions, focus on the relation of upsides and downsides
- You can profit from them by seeking optionality, which means seeking situations with limited downside and exponential upside
- Step changes in AI require further Black Swans, not tinkering with LLMs

### On the (un)importance of forecasts
Nassim Taleb, a famous essayist and statistician, popularized the idea of the Black Swan.
By this, he means unpredictable events with extreme impact.
He argues that our lifes are mostly determined by Black Swans.
While our lifes mostly change incrementally, Black Swans lead to step changes.
They can be positive or negative.



- our lifes are determined by black swan events (as nassim taleb, author of books the black swan and antifragile, puts it)
- otherwise, progress is mostly incremental
- black swans can be positive or negative
- they carry an extreme impact
- example of black swan: transformer -> stepwise increase of performance of ai models -> massive amounts of capital -> further research and progress
- nothing in the past convincingly points to its possibility -> lies outside the realm of regular expectations -> can not be forecasted reliably
- after the event, human nature drives us to create reasonable explanations of why it was inevitable from the start
- in fact, it was not

### Focus on building learning systems
- instead of making decisions based on predictions, build systems that do not suffer, but profit from volatility
- use the barbell strategy: be extremely paranoid about 90% of your resources, use the other 10% of aggressive bets that have unlimited upside
- structure your system about asymmetric bets -> strive for a minimal downside and and exponential upside when becoming lucky
- example: go to a party -> your time investment is relatively small but you may find get to know interesting people
- build intentional redundancy
- this can be multiple streams of income or having cash reserves
- use fast, cheap tinkering -> agile development with short feedback circuits
- enforce skin in the game
- make sure people bear the consequences of their mistakes, by aligning risk and reward
- people will act much more responsibly if they are actually long term responsible, and not bailed out in bad times while receiving big bonuses in good times

### Many KPIs do not convey valuable information
- be sensitive to statistical measures - what information do you actually get?
- if the average room temperature of your flat over the last 10 hours was 20 degrees celcius, but the maximum value was 100 degrees and the minimum was -50 degrees, you might have a problem

### The optimal long-term solution may be out of reach
- caveats: it might take more time than you have for this strategy to pay off - in the meantime, other people may have great success until they are wiped out by the next black swan
- example: relying on only one big enterprise resource planning provider like SAP leads to great long term risks, since this provider will be deeply integrated into the company, giving it enormous leverage - however, resolving this issue may lead to organizational pain for many years and the benefits of this may never be seen since the company can not see what is did not have to endure

### Further step changes in AI require further Black Swans
- the next big step forward in AI requires another black swan
- from the technical perspective, we are incredibly well positioned for this
- huge amounts of capital allow extensive research, limiting technical downside while obtaining astronomical upside
- even a financial correction will not hinder existing AI systems to become more powerful
- It will just lead to resources being focused on increasing the performance of existing systems incrementally rather than exploring completely new realms of AI, as existing AI systems lead to greater revenue with much more certainty
- Until the next black swan, we will be stuck tinkering around with LLMs


